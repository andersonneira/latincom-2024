{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b07a26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#https://pypi.org/project/sklearn-som/  \n",
    "#https://github.com/rileypsmith/sklearn-som/blob/main/sklearn_som/som.py\n",
    "from statistics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn_som.som import SOM\n",
    "from sklearn.cluster import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import HDBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import BisectingKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from s_dbw import S_Dbw\n",
    "from cdbw import CDbw\n",
    "#https://pypi.org/project/s-dbw/\n",
    "#https://pypi.org/project/cdbw/\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "'''\n",
    "data: dados para clusterizar\n",
    "\n",
    "cluster_validity_metric: define qual métrica será usada para identificar o melhor algoritmo (Davies-Bouldin Index, Calinski-Harabasz Index, Silhouette Coefficient)\n",
    "    opcoes: sdbw, cdbw, silhouette_score or calinski_harabasz_score, avg (default)\n",
    "\n",
    "number_clusters: o usuário pode de limitar a busca por quantidade de cluster\n",
    "    2 (default)\n",
    "    None testa vários\n",
    "'''\n",
    "def announce(data, cluster_validity_metric = 'avg', number_clusters = 2):\n",
    "    return selection_mode_default(data, number_clusters, cluster_validity_metric)\n",
    "\n",
    "def selection_mode_default(data, number_clusters, cluster_validity_metric):\n",
    "    resultado = []\n",
    "    algos = algorithms(number_clusters, data.shape[1])\n",
    "\n",
    "    for algo in algos:\n",
    "        score = sdbw = cdbw = kh = db = ss = 0\n",
    "        algo_str = ''\n",
    "        #try:\n",
    "        if(\"SOM\" in str(algo)):\n",
    "            fd = format_data(data)\n",
    "            labels = algo.fit_predict(fd)\n",
    "            algo_str = \"SOM(m=\"+str(algo.m)+\", n=\"+str(algo.n)+\", dim=\"+str(algo.dim)+ \", random_state=0)\"\n",
    "        elif ('GaussianMixture' in str(algo)):\n",
    "            algo.fit(data)\n",
    "            labels = algo.predict(data)\n",
    "            algo_str = str(algo)\n",
    "        else:\n",
    "            algo.fit(data)\n",
    "            labels = algo.labels_\n",
    "            algo_str = str(algo)\n",
    "\n",
    "        if cluster_validity_metric == 'calinski_harabasz_score':\n",
    "            score = metrics.compute_calinski_harabasz_score(data, labels)\n",
    "\n",
    "        if cluster_validity_metric == 'silhouette_score':\n",
    "            score = compute_silhouette_score(data, labels)\n",
    "        \n",
    "        if cluster_validity_metric == 'silhouette_score':\n",
    "            score = compute_silhouette_score(data, labels)\n",
    "\n",
    "        if cluster_validity_metric == 'sdbw':\n",
    "            score = compute_sdbw(data, labels)\n",
    "\n",
    "        if cluster_validity_metric == 'cdbw':\n",
    "            score = compute_cdbw(data, labels)\n",
    "\n",
    "        if cluster_validity_metric == 'avg':\n",
    "            kh = compute_calinski_harabasz_score(data, labels)\n",
    "            ss = compute_silhouette_score(data, labels)\n",
    "            db = compute_davies_bouldin_score(data, labels)\n",
    "            sdbw = compute_sdbw(data, labels)\n",
    "            cdbw = compute_cdbw(data, labels)\n",
    "                \n",
    "#         except:\n",
    "#         score = 0\n",
    "#         else:        \n",
    "        if(cluster_validity_metric == 'avg'):\n",
    "            resultado.append((algo_str, kh, ss, db, sdbw, cdbw))\n",
    "        else:\n",
    "            resultado.append((algo_str, score))\n",
    "                \n",
    "\n",
    "    if(cluster_validity_metric == 'avg'):\n",
    "        temp = pd.DataFrame(resultado, columns=['Algorithm','Calinski_harabasz_score',\n",
    "                                                'Silhouette_score', 'Davies_bouldin_score',\n",
    "                                                'SDBW', 'CDBW'])  \n",
    "        colunas_minmax = ['Calinski_harabasz_score','Silhouette_score', 'Davies_bouldin_score',\n",
    "                          'SDBW', 'CDBW']\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(temp[colunas_minmax])\n",
    "        temp2 = pd.DataFrame(data=scaler.transform(temp[colunas_minmax]),\n",
    "                     index=[i for i in range(temp.shape[0])],\n",
    "                     columns=colunas_minmax)\n",
    "        df =  pd.concat([temp, temp2], axis=1).reindex(temp.index)\n",
    "        df.columns =['Algorithm','Calinski_harabasz_score',\n",
    "                                                'Silhouette_score', 'Davies_bouldin_score',\n",
    "                                                'SDBW', 'CDBW',\n",
    "                                                'Calinski_harabasz_score_minmax',\n",
    "                                                'Silhouette_score_minmax',\n",
    "                                                'Davies_bouldin_score_minmax',\n",
    "                                                'SDBW_minmax', 'CDBW_minmax']\n",
    "                       \n",
    "#         mean = df[['Calinski_harabasz_score_minmax', 'Silhouette_score_minmax',\n",
    "#                    'Davies_bouldin_score_minmax',\n",
    "#                    'SDBW_minmax', 'CDBW_minmax']].apply([harmonic_mean],axis=1)\n",
    "        \n",
    "        norm_db = df[['Davies_bouldin_score_minmax']].apply(lambda x:  1 - x,axis=1)\n",
    "        norm_sd = df[['SDBW_minmax']].apply(lambda x:  1 - x,axis=1)\n",
    "        \n",
    "        df1 =  pd.concat([df, norm_db, norm_sd], axis=1).reindex(df.index)\n",
    "        \n",
    "        df1.columns=['Algorithm','Calinski_harabasz_score',\n",
    "                                                'Silhouette_score', 'Davies_bouldin_score',\n",
    "                                                'SDBW','CDBW',\n",
    "                                                'Calinski_harabasz_score_minmax',\n",
    "                                                'Silhouette_score_minmax',\n",
    "                                                'Davies_bouldin_score_minmax',\n",
    "                                                'SDBW_minmax', 'CDBW_minmax',\n",
    "                                                'Davies_bouldin_score_minmax_normalizado',\n",
    "                                                'SDBW_minmax_normalizado']\n",
    "            \n",
    "        df1 =  df1[['Algorithm','Calinski_harabasz_score',\n",
    "                                                'Silhouette_score', 'Davies_bouldin_score',\n",
    "                                                'SDBW','CDBW',\n",
    "                                                'Davies_bouldin_score_minmax',\n",
    "                                                'SDBW_minmax',\n",
    "                                                'Calinski_harabasz_score_minmax',\n",
    "                                                'Silhouette_score_minmax',\n",
    "                                                'CDBW_minmax',\n",
    "                                                'Davies_bouldin_score_minmax_normalizado',\n",
    "                                                'SDBW_minmax_normalizado' ]]\n",
    "        \n",
    "        mean = df1[['Calinski_harabasz_score_minmax',\n",
    "                    'Silhouette_score_minmax',\n",
    "                    'CDBW_minmax',\n",
    "                    'Davies_bouldin_score_minmax_normalizado',\n",
    "                    'SDBW_minmax_normalizado']].apply(['mean'],axis=1)\n",
    "        \n",
    "        f = pd.concat([df1, mean], axis=1).reindex(df1.index).sort_values(\n",
    "            by=['mean', 'Algorithm'], ascending=False)   \n",
    "        final = f[['Algorithm','mean',\n",
    "                        'Calinski_harabasz_score_minmax',\n",
    "                        'Silhouette_score_minmax',\n",
    "                        'CDBW_minmax',\n",
    "                        'Davies_bouldin_score_minmax_normalizado',\n",
    "                        'SDBW_minmax_normalizado',\n",
    "                        'Calinski_harabasz_score',\n",
    "                        'Silhouette_score', 'Davies_bouldin_score',\n",
    "                        'SDBW','CDBW',\n",
    "                        'Davies_bouldin_score_minmax',\n",
    "                        'SDBW_minmax',\n",
    "                        ]]\n",
    "        return final.reset_index(drop=True)\n",
    "    \n",
    "    else:\n",
    "        return resultado\n",
    "    \n",
    "def compute_davies_bouldin_score(data, labels):\n",
    "    score = 0\n",
    "    try:\n",
    "        score = metrics.davies_bouldin_score(data, labels)\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def compute_silhouette_score(data, labels):\n",
    "    score = 0\n",
    "    try:\n",
    "        score = metrics.silhouette_score(data, labels)\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "        \n",
    "def compute_calinski_harabasz_score(data, labels):\n",
    "    score = 0\n",
    "    try:\n",
    "        score = metrics.calinski_harabasz_score(data, labels)\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def compute_sdbw(data, labels):\n",
    "    score = 0 \n",
    "    try:\n",
    "        fd = format_data(data)\n",
    "        score = 1 - S_Dbw(fd, labels)\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def compute_cdbw(data, labels):\n",
    "    score = 0 \n",
    "    try:\n",
    "        fd = format_data(data)\n",
    "        score = CDbw(fd, labels)\n",
    "    except:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def format_data(data):\n",
    "    formated_data = []\n",
    "    for i in range(data.index[0], data.index[0] + len(data)):\n",
    "        temp = []\n",
    "        for col in data.columns:\n",
    "            temp.append(data[col][i])\n",
    "        formated_data.append(temp)\n",
    "    return np.asarray(formated_data)\n",
    "\n",
    "def algorithms(number_clusters, ndim:3):\n",
    "    algos = []\n",
    "    algos.append(MeanShift())\n",
    "    print('**********************************************')\n",
    "    print(number_clusters)\n",
    "    if number_clusters == None:\n",
    "        for i in range(2,11): \n",
    "            algos.append(KMeans(n_clusters=i, random_state=0)) \n",
    "            algos.append(Birch(n_clusters=i))\n",
    "            algos.append(DBSCAN(eps=i*0.1, min_samples=i))\n",
    "            algos.append(OPTICS(min_samples=i))\n",
    "            algos.append(BisectingKMeans(n_clusters=i, random_state=0)) \n",
    "            algos.append(SOM(m=i, n=1, dim=ndim, random_state = 0))\n",
    "            algos.append(GaussianMixture(n_components=i, random_state=0))\n",
    "            algos.append(AgglomerativeClustering(n_clusters=i))\n",
    "            algos.append(HDBSCAN(min_cluster_size=i))           \n",
    "            algos.append(SpectralClustering(n_clusters=i, affinity= 'poly', random_state=0))\n",
    "        for i in range (2,6):\n",
    "            algos.append(AffinityPropagation(damping=(i*0.1)+0.3, random_state=0))\n",
    "            \n",
    "    else:\n",
    "        algos.append(KMeans(n_clusters=number_clusters, random_state=0)) \n",
    "        algos.append(Birch(n_clusters=number_clusters))\n",
    "        algos.append(BisectingKMeans(n_clusters=number_clusters, random_state=0)) \n",
    "        algos.append(GaussianMixture(n_components=number_clusters, random_state=0))\n",
    "        algos.append(AgglomerativeClustering(n_clusters=number_clusters))\n",
    "        algos.append(SpectralClustering(n_clusters=number_clusters, affinity= 'poly', random_state=0))\n",
    "        algos.append(SOM(m=number_clusters, n=1,dim=ndim, random_state = 0))\n",
    "        algos.append(AffinityPropagation(random_state=0))\n",
    "        algos.append(DBSCAN())\n",
    "        algos.append(OPTICS())\n",
    "        algos.append(HDBSCAN(min_cluster_size=number_clusters))\n",
    "    return algos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
